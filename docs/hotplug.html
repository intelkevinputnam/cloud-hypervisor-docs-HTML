<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Cloud Hypervisor Hot Plug &mdash; Cloud Hypervisor  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Intel SGX" href="intel_sgx.html" />
    <link rel="prev" title="GDB Support" href="gdb.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../README.html" class="icon icon-home"> Cloud Hypervisor
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="api.html">Cloud Hypervisor API</a></li>
<li class="toctree-l1"><a class="reference internal" href="arm64.html">How to build and test Cloud Hypervisor on AArch64</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu.html">CPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom-image.html">How to create a custom Ubuntu image</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug-port.html"><code class="docutils literal notranslate"><span class="pre">cloud-hypervisor</span></code> debug IO port</a></li>
<li class="toctree-l1"><a class="reference internal" href="device_model.html">Device Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="fs.html">How to use virtio-fs</a></li>
<li class="toctree-l1"><a class="reference internal" href="fuzzing.html">Fuzzing in Cloud Hypervisor</a></li>
<li class="toctree-l1"><a class="reference internal" href="gdb.html">GDB Support</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Cloud Hypervisor Hot Plug</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#kernel-support">Kernel support</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cpu-hot-plug">CPU Hot Plug</a></li>
<li class="toctree-l2"><a class="reference internal" href="#memory-hot-plug">Memory Hot Plug</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#acpi-method">ACPI method</a></li>
<li class="toctree-l3"><a class="reference internal" href="#virtio-mem-method">virtio-mem method</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pci-device-hot-plug">PCI Device Hot Plug</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#add-vfio-device">Add VFIO Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#add-disk-device">Add Disk Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#add-fs-device">Add Fs Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#add-net-device">Add Net Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#add-pmem-device">Add Pmem Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#add-vsock-device">Add Vsock Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#common-across-all-pci-devices">Common Across All PCI Devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="#remove-pci-device">Remove PCI device</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="intel_sgx.html">Intel SGX</a></li>
<li class="toctree-l1"><a class="reference internal" href="intel_tdx.html">Intel TDX</a></li>
<li class="toctree-l1"><a class="reference internal" href="io_throttling.html">I/O Throttling</a></li>
<li class="toctree-l1"><a class="reference internal" href="iommu.html">Virtual IOMMU</a></li>
<li class="toctree-l1"><a class="reference internal" href="live_migration.html">Live Migration</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="macvtap-bridge.html">Using MACVTAP to Bridge onto Host Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="memory.html">Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiling.html">Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="seccomp.html">Seccomp filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="snapshot_restore.html">Snapshot and Restore</a></li>
<li class="toctree-l1"><a class="reference internal" href="uefi.html">UEFI Boot</a></li>
<li class="toctree-l1"><a class="reference internal" href="uefi.html#links">Links</a></li>
<li class="toctree-l1"><a class="reference internal" href="vfio.html">Cloud Hypervisor VFIO HOWTO</a></li>
<li class="toctree-l1"><a class="reference internal" href="vfio-user.html">Cloud Hypervisor VFIO-user HOWTO</a></li>
<li class="toctree-l1"><a class="reference internal" href="vhost-user-blk-testing.html">How to test vhost-user-blk with SPDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="vhost-user-net-testing.html">How to test Vhost-user net with OpenVSwitch/DPDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="virtiofs-root.html">HOWTO VirtioFS rootfs</a></li>
<li class="toctree-l1"><a class="reference internal" href="windows.html">Windows Support</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../README.html">Cloud Hypervisor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../README.html" class="icon icon-home"></a> &raquo;</li>
      <li>Cloud Hypervisor Hot Plug</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/docs/hotplug.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="cloud-hypervisor-hot-plug">
<h1>Cloud Hypervisor Hot Plug<a class="headerlink" href="#cloud-hypervisor-hot-plug" title="Permalink to this headline"></a></h1>
<p>Currently Cloud Hypervisor supports hot plugging of CPUs devices (x86 only), PCI devices and memory resizing.</p>
<section id="kernel-support">
<h2>Kernel support<a class="headerlink" href="#kernel-support" title="Permalink to this headline"></a></h2>
<p>For hotplug on Cloud Hypervisor ACPI GED support is needed. This can either be achieved by turning on <code class="docutils literal notranslate"><span class="pre">CONFIG_ACPI_REDUCED_HARDWARE_ONLY</span></code>
or by using this kernel patch (available in 5.5-rc1 and later): https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/patch/drivers/acpi/Makefile?id=ac36d37e943635fc072e9d4f47e40a48fbcdb3f0</p>
</section>
<section id="cpu-hot-plug">
<h2>CPU Hot Plug<a class="headerlink" href="#cpu-hot-plug" title="Permalink to this headline"></a></h2>
<p>Extra vCPUs can be added and removed from a running <code class="docutils literal notranslate"><span class="pre">cloud-hypervisor</span></code> instance. This is controlled by two mechanisms:</p>
<ol class="simple">
<li><p>Specifying a number of maximum potential vCPUs that is greater than the number of default (boot) vCPUs.</p></li>
<li><p>Making a HTTP API request to the VMM to ask for the additional vCPUs to be added.</p></li>
</ol>
<p>To use CPU hotplug start the VM with the number of max vCPUs greater than the number of boot vCPUs, e.g.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">pushd</span> <span class="nv">$CLOUDH</span>
$ sudo setcap cap_net_admin+ep ./cloud-hypervisor/target/release/cloud-hypervisor
$ ./cloud-hypervisor/target/release/cloud-hypervisor <span class="se">\</span>
	--kernel custom-vmlinux.bin <span class="se">\</span>
	--cmdline <span class="s2">&quot;console=ttyS0 console=hvc0 root=/dev/vda1 rw&quot;</span> <span class="se">\</span>
	--disk <span class="nv">path</span><span class="o">=</span>focal-server-cloudimg-amd64.raw <span class="se">\</span>
	--cpus <span class="nv">boot</span><span class="o">=</span><span class="m">4</span>,max<span class="o">=</span><span class="m">8</span> <span class="se">\</span>
	--memory <span class="nv">size</span><span class="o">=</span>1024M <span class="se">\</span>
	--net <span class="s2">&quot;tap=,mac=,ip=,mask=&quot;</span> <span class="se">\</span>
	--rng <span class="se">\</span>
	--api-socket<span class="o">=</span>/tmp/ch-socket
$ <span class="nb">popd</span>
</pre></div>
</div>
<p>Notice the addition of <code class="docutils literal notranslate"><span class="pre">--api-socket=/tmp/ch-socket</span></code> and a <code class="docutils literal notranslate"><span class="pre">max</span></code> parameter on <code class="docutils literal notranslate"><span class="pre">--cpus</span> <span class="pre">boot=4,max=8</span></code>.</p>
<p>To ask the VMM to add additional vCPUs then use the resize API:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./ch-remote --api-socket<span class="o">=</span>/tmp/ch-socket resize --cpus <span class="m">8</span>
</pre></div>
</div>
<p>The extra vCPU threads will be created and advertised to the running kernel. The kernel does not bring up the CPUs immediately and instead the user must “online” them from inside the VM:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@ch-guest ~ <span class="c1"># lscpu | grep list:</span>
On-line CPU<span class="o">(</span>s<span class="o">)</span> list:             <span class="m">0</span>-3
Off-line CPU<span class="o">(</span>s<span class="o">)</span> list:            <span class="m">4</span>-7
root@ch-guest ~ <span class="c1"># echo 1 | tee /sys/devices/system/cpu/cpu[4,5,6,7]/online</span>
<span class="m">1</span>
root@ch-guest ~ <span class="c1"># lscpu | grep list:</span>
On-line CPU<span class="o">(</span>s<span class="o">)</span> list:             <span class="m">0</span>-7
</pre></div>
</div>
<p>After a reboot the added CPUs will remain.</p>
<p>Removing CPUs works similarly by reducing the number in the “desired_vcpus” field of the reisze API. The CPUs will be automatically offlined inside the guest so there is no need to run any commands inside the guest:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./ch-remote --api-socket<span class="o">=</span>/tmp/ch-socket resize --cpus <span class="m">2</span>
</pre></div>
</div>
<p>As per adding CPUs to the guest, after a reboot the VM will be running with the reduced number of vCPUs.</p>
</section>
<section id="memory-hot-plug">
<h2>Memory Hot Plug<a class="headerlink" href="#memory-hot-plug" title="Permalink to this headline"></a></h2>
<section id="acpi-method">
<h3>ACPI method<a class="headerlink" href="#acpi-method" title="Permalink to this headline"></a></h3>
<p>Extra memory can be added from a running <code class="docutils literal notranslate"><span class="pre">cloud-hypervisor</span></code> instance. This is controlled by two mechanisms:</p>
<ol class="simple">
<li><p>Allocating some of the guest physical address space for hotplug memory.</p></li>
<li><p>Making a HTTP API request to the VMM to ask for a new amount of RAM to be assigned to the VM. In the case of expanding the memory for the VM the new memory will be hotplugged into the running VM, if reducing the size of the memory then change will take effect after the next reboot.</p></li>
</ol>
<p>To use memory hotplug start the VM specifying some size RAM in the <code class="docutils literal notranslate"><span class="pre">hotplug_size</span></code> parameter to the memory configuration. Not all the memory specified in this parameter will be available to hotplug as there are spacing and alignment requirements so it is recommended to make it larger than the hotplug RAM needed.</p>
<p>Because the ACPI method is the default, there is no need to add the extra option <code class="docutils literal notranslate"><span class="pre">hotplug_method=acpi</span></code>.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">pushd</span> <span class="nv">$CLOUDH</span>
$ sudo setcap cap_net_admin+ep ./cloud-hypervisor/target/release/cloud-hypervisor
$ ./cloud-hypervisor/target/release/cloud-hypervisor <span class="se">\</span>
	--kernel custom-vmlinux.bin <span class="se">\</span>
	--cmdline <span class="s2">&quot;console=ttyS0 console=hvc0 root=/dev/vda1 rw&quot;</span> <span class="se">\</span>
	--disk <span class="nv">path</span><span class="o">=</span>focal-server-cloudimg-amd64.raw <span class="se">\</span>
	--cpus <span class="nv">boot</span><span class="o">=</span><span class="m">4</span>,max<span class="o">=</span><span class="m">8</span> <span class="se">\</span>
	--memory <span class="nv">size</span><span class="o">=</span>1024M,hotplug_size<span class="o">=</span>8192M <span class="se">\</span>
	--net <span class="s2">&quot;tap=,mac=,ip=,mask=&quot;</span> <span class="se">\</span>
	--rng <span class="se">\</span>
	--api-socket<span class="o">=</span>/tmp/ch-socket
$ <span class="nb">popd</span>
</pre></div>
</div>
<p>Before issuing the API request it is necessary to run the following command inside the VM to make it automatically online the added memory:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@ch-guest ~ <span class="c1"># echo online | sudo tee /sys/devices/system/memory/auto_online_blocks</span>
</pre></div>
</div>
<p>To ask the VMM to expand the RAM for the VM:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./ch-remote --api-socket<span class="o">=</span>/tmp/ch-socket resize --memory 3G
</pre></div>
</div>
<p>The new memory is now available to use inside the VM:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>free -h
              total        used        free      shared  buff/cache   available
Mem:          <span class="m">3</span>.0Gi        71Mi       <span class="m">2</span>.8Gi       <span class="m">0</span>.0Ki        47Mi       <span class="m">2</span>.8Gi
Swap:          32Mi          0B        32Mi
</pre></div>
</div>
<p>Due to guest OS limitations is is necessary to ensure that amount of memory added (between currently assigned RAM and that which is desired) is a multiple of 128MiB.</p>
<p>The same API can also be used to reduce the desired RAM for a VM but the change will not be applied until the VM is rebooted.</p>
<p>Memory and CPU resizing can be combined together into the same HTTP API request.</p>
</section>
<section id="virtio-mem-method">
<h3>virtio-mem method<a class="headerlink" href="#virtio-mem-method" title="Permalink to this headline"></a></h3>
<p>Extra memory can be added and removed from a running Cloud Hypervisor instance. This is controlled by two mechanisms:</p>
<ol class="simple">
<li><p>Allocating some of the guest physical address space for hotplug memory.</p></li>
<li><p>Making a HTTP API request to the VMM to ask for a new amount of RAM to be assigned to the VM.</p></li>
</ol>
<p>To use memory hotplug start the VM specifying some size RAM in the <code class="docutils literal notranslate"><span class="pre">hotplug_size</span></code> parameter along with <code class="docutils literal notranslate"><span class="pre">hotplug_method=virtio-mem</span></code> to the memory configuration.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">pushd</span> <span class="nv">$CLOUDH</span>
$ sudo setcap cap_net_admin+ep ./cloud-hypervisor/target/release/cloud-hypervisor
$ ./cloud-hypervisor/target/release/cloud-hypervisor <span class="se">\</span>
	--kernel custom-vmlinux.bin <span class="se">\</span>
	--cmdline <span class="s2">&quot;console=ttyS0 console=hvc0 root=/dev/vda1 rw&quot;</span> <span class="se">\</span>
	--disk <span class="nv">path</span><span class="o">=</span>focal-server-cloudimg-amd64.raw <span class="se">\</span>
	--memory <span class="nv">size</span><span class="o">=</span>1024M,hotplug_size<span class="o">=</span>8192M,hotplug_method<span class="o">=</span>virtio-mem <span class="se">\</span>
	--net <span class="s2">&quot;tap=,mac=,ip=,mask=&quot;</span> <span class="se">\</span>
	--api-socket<span class="o">=</span>/tmp/ch-socket
$ <span class="nb">popd</span>
</pre></div>
</div>
<p>To ask the VMM to expand the RAM for the VM (request is in bytes):</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./ch-remote --api-socket<span class="o">=</span>/tmp/ch-socket resize --memory 3G
</pre></div>
</div>
<p>The new memory is now available to use inside the VM:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>free -h
              total        used        free      shared  buff/cache   available
Mem:          <span class="m">3</span>.0Gi        71Mi       <span class="m">2</span>.8Gi       <span class="m">0</span>.0Ki        47Mi       <span class="m">2</span>.8Gi
Swap:          32Mi          0B        32Mi
</pre></div>
</div>
<p>The same API can also be used to reduce the desired RAM for a VM. It is important to note that reducing RAM size might only partially work, as the guest might be using some of it.</p>
</section>
</section>
<section id="pci-device-hot-plug">
<h2>PCI Device Hot Plug<a class="headerlink" href="#pci-device-hot-plug" title="Permalink to this headline"></a></h2>
<p>Extra PCI devices can be added and removed from a running <code class="docutils literal notranslate"><span class="pre">cloud-hypervisor</span></code> instance. This is controlled by making a HTTP API request to the VMM to ask for the additional device to be added, or for the existing device to be removed.</p>
<p>Note: On AArch64 platform, PCI device hotplug can only be achieved using ACPI. Please refer to the <a class="reference external" href="arm64.html#uefi-booting">documentation</a> for more information.</p>
<p>To use PCI device hotplug start the VM with the HTTP server.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ sudo setcap cap_net_admin+ep ./cloud-hypervisor/target/release/cloud-hypervisor
$ ./cloud-hypervisor/target/release/cloud-hypervisor <span class="se">\</span>
	--kernel custom-vmlinux.bin <span class="se">\</span>
	--cmdline <span class="s2">&quot;console=ttyS0 console=hvc0 root=/dev/vda1 rw&quot;</span> <span class="se">\</span>
	--disk <span class="nv">path</span><span class="o">=</span>focal-server-cloudimg-amd64.raw <span class="se">\</span>
	--cpus <span class="nv">boot</span><span class="o">=</span><span class="m">4</span> <span class="se">\</span>
	--memory <span class="nv">size</span><span class="o">=</span>1024M <span class="se">\</span>
	--net <span class="s2">&quot;tap=,mac=,ip=,mask=&quot;</span> <span class="se">\</span>
	--api-socket<span class="o">=</span>/tmp/ch-socket
</pre></div>
</div>
<p>Notice the addition of <code class="docutils literal notranslate"><span class="pre">--api-socket=/tmp/ch-socket</span></code>.</p>
<section id="add-vfio-device">
<h3>Add VFIO Device<a class="headerlink" href="#add-vfio-device" title="Permalink to this headline"></a></h3>
<p>To ask the VMM to add additional VFIO device then use the <code class="docutils literal notranslate"><span class="pre">add-device</span></code> API.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./ch-remote --api-socket<span class="o">=</span>/tmp/ch-socket add-device <span class="nv">path</span><span class="o">=</span>/sys/bus/pci/devices/0000:01:00.0/
</pre></div>
</div>
</section>
<section id="add-disk-device">
<h3>Add Disk Device<a class="headerlink" href="#add-disk-device" title="Permalink to this headline"></a></h3>
<p>To ask the VMM to add additional disk device then use the <code class="docutils literal notranslate"><span class="pre">add-disk</span></code> API.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./ch-remote --api-socket<span class="o">=</span>/tmp/ch-socket add-disk <span class="nv">path</span><span class="o">=</span>/foo/bar/cloud.img
</pre></div>
</div>
</section>
<section id="add-fs-device">
<h3>Add Fs Device<a class="headerlink" href="#add-fs-device" title="Permalink to this headline"></a></h3>
<p>To ask the VMM to add additional fs device then use the <code class="docutils literal notranslate"><span class="pre">add-fs</span></code> API.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./ch-remote --api-socket<span class="o">=</span>/tmp/ch-socket add-fs <span class="nv">tag</span><span class="o">=</span>myfs,socket<span class="o">=</span>/foo/bar/virtiofs.sock
</pre></div>
</div>
</section>
<section id="add-net-device">
<h3>Add Net Device<a class="headerlink" href="#add-net-device" title="Permalink to this headline"></a></h3>
<p>To ask the VMM to add additional network device then use the <code class="docutils literal notranslate"><span class="pre">add-net</span></code> API.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./ch-remote --api-socket<span class="o">=</span>/tmp/ch-socket add-net <span class="nv">tap</span><span class="o">=</span>chtap0
</pre></div>
</div>
</section>
<section id="add-pmem-device">
<h3>Add Pmem Device<a class="headerlink" href="#add-pmem-device" title="Permalink to this headline"></a></h3>
<p>To ask the VMM to add additional PMEM device then use the <code class="docutils literal notranslate"><span class="pre">add-pmem</span></code> API.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./ch-remote --api-socket<span class="o">=</span>/tmp/ch-socket add-pmem <span class="nv">file</span><span class="o">=</span>/foo/bar.cloud.img
</pre></div>
</div>
</section>
<section id="add-vsock-device">
<h3>Add Vsock Device<a class="headerlink" href="#add-vsock-device" title="Permalink to this headline"></a></h3>
<p>To ask the VMM to add additional vsock device then use the <code class="docutils literal notranslate"><span class="pre">add-vsock</span></code> API.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./ch-remote --api-socket<span class="o">=</span>/tmp/ch-socket add-vsock <span class="nv">cid</span><span class="o">=</span><span class="m">3</span>,socket<span class="o">=</span>/foo/bar/vsock.sock
</pre></div>
</div>
</section>
<section id="common-across-all-pci-devices">
<h3>Common Across All PCI Devices<a class="headerlink" href="#common-across-all-pci-devices" title="Permalink to this headline"></a></h3>
<p>The extra PCI device will be created and advertised to the running kernel. The new device can be found by checking the list of PCI devices.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@ch-guest ~ <span class="c1"># lspci</span>
<span class="m">00</span>:00.0 Host bridge: Intel Corporation Device 0d57
<span class="m">00</span>:01.0 Unassigned class <span class="o">[</span>ffff<span class="o">]</span>: Red Hat, Inc. Virtio console <span class="o">(</span>rev <span class="m">01</span><span class="o">)</span>
<span class="m">00</span>:02.0 Mass storage controller: Red Hat, Inc. Virtio block device <span class="o">(</span>rev <span class="m">01</span><span class="o">)</span>
<span class="m">00</span>:03.0 Unassigned class <span class="o">[</span>ffff<span class="o">]</span>: Red Hat, Inc. Virtio RNG <span class="o">(</span>rev <span class="m">01</span><span class="o">)</span>
</pre></div>
</div>
<p>After a reboot the added PCI device will remain.</p>
</section>
<section id="remove-pci-device">
<h3>Remove PCI device<a class="headerlink" href="#remove-pci-device" title="Permalink to this headline"></a></h3>
<p>Removing a PCI device works the same way for all kind of PCI devices. The unique identifier related to the device must be provided. This identifier can be provided by the user when adding the new device, or by default Cloud Hypervisor will assign one.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./ch-remote --api-socket<span class="o">=</span>/tmp/ch-socket remove-device _disk0
</pre></div>
</div>
<p>As per adding a PCI device to the guest, after a reboot the VM will be running without the removed PCI device.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="gdb.html" class="btn btn-neutral float-left" title="GDB Support" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="intel_sgx.html" class="btn btn-neutral float-right" title="Intel SGX" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, various.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>